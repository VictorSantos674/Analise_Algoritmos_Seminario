# Arquitetura Apache Spark - Anota√ß√µes Detalhadas

## üî• 3) Arquitetura Spark

### üîπ Cluster Mode: Driver, Executors, Worker Nodes

* **Driver Program**:

  * Aplica√ß√£o principal do Spark.
  * Respons√°vel por:

    * Criar SparkContext/SparkSession.
    * Construir o DAG.
    * Dividir em stages.
    * Enviar tasks aos executors.

* **Cluster Manager**:

  * Aloca recursos do cluster.
  * Tipos: YARN, Mesos, Kubernetes, Spark Standalone.

* **Worker Nodes**:

  * M√°quinas que executam as tarefas.

* **Executors**:

  * Processos que executam as tasks e armazenam dados em cache.

---

### üîπ DAG e Ciclo de Vida de uma Aplica√ß√£o Spark 

* **DAG (Directed Acyclic Graph)**:

  * Representa transforma√ß√µes aplicadas aos dados.
  * Sem ciclos; garante fim da execu√ß√£o.

* **Fases**:

  1. Cria√ß√£o do SparkContext.
  2. DAG de transforma√ß√µes (lazy evaluation).
  3. A√ß√£o ‚Üí gera plano de execu√ß√£o.
  4. DAG ‚Üí stages ‚Üí tasks.
  5. Executors executam as tasks.

---

### üîπ Comparativo com Outras Abordagens Paralelas 

| Caracter√≠stica         | Hadoop MapReduce | Apache Spark             |
| ---------------------- | ---------------- | ------------------------ |
| Execu√ß√£o               | Disco            | Mem√≥ria (RAM)            |
| Velocidade             | Lenta            | Muito r√°pida             |
| API                    | Limitada         | Rica (RDD, DataFrame...) |
| Suporte a ML/Streaming | Limitado         | Completo                 |
| Toler√¢ncia a falhas    | Alta             | Moderada                 |

---

### ‚úÖ Divis√£o em Stages e Tasks 

* **Stage**:

  * Fase com tasks que n√£o exigem shuffle.

* **Task**:

  * Unidade m√≠nima de execu√ß√£o.
  * Uma por parti√ß√£o.

* **Processo**:

  1. DAG √© analisado.
  2. Dividido em stages.
  3. Cada stage em tasks.
  4. Tasks enviadas aos executors.

#### Exemplo:

```python
rdd = sc.textFile("arquivo.txt")
rdd2 = rdd.map(lambda x: x.split(","))
rdd3 = rdd2.groupByKey()
rdd4 = rdd3.count()
```

* `groupByKey()` causa shuffle ‚Üí gera dois stages.

---

### ‚úÖ Shuffle, Narrow vs Wide Transformations 

#### Narrow Transformations (sem shuffle):

* Ex: `map()`, `filter()`
* Parti√ß√£o de entrada ‚Üí uma de sa√≠da.
* Mais eficientes.

#### Wide Transformations (com shuffle):

* Ex: `groupByKey()`, `join()`
* Parti√ß√£o de sa√≠da depende de v√°rias de entrada.
* Gera troca de dados entre n√≥s.

#### Shuffle:

* Redistribui√ß√£o de dados.
* Envolve:

  * Escrita/leitura em disco,
  * Tr√°fego de rede.

#### Dicas:

* Prefira `reduceByKey()` a `groupByKey()`.
* Use `broadcast()` para joins otimizados.

---

### üìä Exemplo Completo

```python
rdd = sc.textFile("dados.csv")
rdd1 = rdd.map(lambda x: x.split(","))
rdd2 = rdd1.map(lambda x: (x[0], int(x[1])))
rdd3 = rdd2.reduceByKey(lambda a, b: a + b)
```

* `map()` ‚Üí narrow.
* `reduceByKey()` ‚Üí wide (shuffle).
* Dois stages s√£o gerados.
